# fmi-unibuc-ia.github.io/ia
import numpy as np
cale = 'D:/An II/IA/ML/data/'
train_images = np.loadtxt(cale + 'train_images.txt')
train_labels = np.loadtxt(cale + 'train_labels.txt', 'int')
test_images = np.loadtxt(cale + 'test_images.txt')
test_labels = np.loadtxt(cale + 'test_labels.txt', 'int')


class NaiveBayes:
    def __init__(self, num_bins):
        self.bins = np.linspace(start=0, stop=255, num=num_bins)
        self.num_bins = num_bins

    def values_to_bins(self, matrice_imagini):
        return np.digitize(matrice_imagini, self.bins) - 1

    def fit(self, train_images, train_labels):
        # aplicam histograma

        train_images = self.values_to_bins(train_images)

        # calculam P(c) si P(x|c)
        # dimensiunea lui P(c) = 1 x num_classes
        # dimensiunea lui P(x|c) = num_features X num_bins X num_classes
        pc = np.zeros((np.unique(train_labels).shape[0]))
        print('toate clasele pe care le avem:\n', np.unique(train_labels))
        for class_val in np.unique(train_labels):
            pc[class_val] = \
                sum(train_labels == class_val) / train_labels.shape[0]
        # P(x/c)
        pxc = np.zeros((train_images.shape[1], self.num_bins, \
                        np.unique(train_labels).shape[0]))
        for i in range(train_images.shape[1]):
            for class_val in np.unique(train_labels):
                imgs_in_class_val = train_images[train_labels == class_val, :]
                # for k in range(16):
                #     plt.subplot(4,4,k+1)
                #     image = imgs_in_class_val[k, :] # prima imagine
                #     image = np.reshape(image, (28, 28))
                #     io.imshow(image.astype(np.uint8))
                # io.show()

                for j in range(self.num_bins):
                    numar_bins_pe_feature = sum(imgs_in_class_val[:,i] == j)
                    pxc[i, j, class_val] = \
                        numar_bins_pe_feature / imgs_in_class_val.shape[0]
        self.pc = pc
        self.pxc = pxc + 1e-10
        return pc, pxc

    def predict(self, test_images):
        # dimensiunea lui P(x|c) = num_features X num_bins X num_classes
        # dimensiunea lui predictions_classes = num_features X num_classes

        test_images = self.values_to_bins(test_images)
        predictions_classes = np.zeros((test_images.shape[0],
                                        len(np.unique(train_labels))))
        for img_idx in range(test_images.shape[0]):
            for class_val in np.unique(train_labels):
                prbabnb = np.log(self.pc[class_val])
                # for j in range(self.num_bins):
                for i in range(test_images.shape[1]):
                    prbabnb += np.log(self.pxc[i,test_images[img_idx, i],
                                               class_val])
                predictions_classes[img_idx, class_val] = prbabnb

        predicted_labels = np.zeros((test_images.shape[0]))
        for img_idx in range(predictions_classes.shape[0]):
            predicted_labels[img_idx] = \
                np.argmax(predictions_classes[img_idx,:])
        return predicted_labels

    def evaluate(self, pred_labels, real_labels):
        aux = 0
        for i in range(len(pred_labels)):
            if pred_labels[i] == real_labels[i]:
                aux += 1
        return aux / len(pred_labels)
        # alta metoda:
        # pred_labels = np.array(pred_labels)
        # real_labels = np.array(real_labels)
        # return sum(real_labels == pred_labels) / pred_labels.shape[0]


print(np.zeros(np.unique(train_labels).shape[0]))
ob = NaiveBayes(10)
pc, pxc = ob.fit(train_images, train_labels)
predicted_labels = ob.predict(test_images)
print(ob.evaluate(predicted_labels, test_labels))
# print(pc)
# print(sum(pc))
# for i in range(pxc.shape[0]):
#     print(pxc[i,:,:])



